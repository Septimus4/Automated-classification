{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22307418",
   "metadata": {},
   "source": [
    "# Phase 5: Hyperparameter Tuning & Interpretability - TechNova Partners\n",
    "\n",
    "**Objective**: Optimize the best-performing models from Phase 4 and provide interpretability insights for business understanding.\n",
    "\n",
    "**Key Findings from Phase 4**:\n",
    "- Best Model: Threshold Optimized Random Forest (F1=0.5172)\n",
    "- Top 3 Models identified for tuning\n",
    "- 269% improvement over baseline achieved\n",
    "\n",
    "**Phase 5 Goals**:\n",
    "1. **Hyperparameter Tuning** - Optimize top 3 models using GridSearchCV\n",
    "2. **Feature Importance Analysis** - Understand key predictors\n",
    "3. **SHAP Analysis** - Provide model interpretability\n",
    "4. **Business Insights** - Translate findings to actionable recommendations\n",
    "\n",
    "**Success Metrics**: Further improve F1-score and provide interpretable insights\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f4fd9b",
   "metadata": {},
   "source": [
    "## 1. Environment Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "id": "44962503",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:15:41.832191Z",
     "start_time": "2025-07-23T13:15:41.681021Z"
    }
   },
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, \n",
    "    precision_score, recall_score, f1_score, \n",
    "    roc_auc_score, roc_curve, precision_recall_curve\n",
    ")\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Interpretability\n",
    "import shap\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# System\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Environment setup complete\")\n",
    "print(\"Phase 5: Hyperparameter Tuning & Interpretability\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup complete\n",
      "Phase 5: Hyperparameter Tuning & Interpretability\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "c3071c11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:15:42.245329Z",
     "start_time": "2025-07-23T13:15:41.836298Z"
    }
   },
   "source": [
    "# Setup robust path handling and load data\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to Python path and setup environment\n",
    "current_dir = Path.cwd()\n",
    "project_root = current_dir\n",
    "while project_root != project_root.parent:\n",
    "    if (project_root / 'pyproject.toml').exists() or (project_root / 'hr_analytics_utils.py').exists():\n",
    "        break\n",
    "    project_root = project_root.parent\n",
    "\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import utilities and setup environment\n",
    "from hr_analytics_utils import (\n",
    "    setup_notebook_environment,\n",
    "    load_modeling_data_from_db, \n",
    "    load_previous_model_results,\n",
    "    print_database_status\n",
    ")\n",
    "\n",
    "# Setup environment\n",
    "env_info = setup_notebook_environment()\n",
    "\n",
    "# Check database status\n",
    "print_database_status()\n",
    "\n",
    "# Load features and target from database using robust paths\n",
    "print(\"\\nLOADING MODELING DATA FROM DATABASE\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "X, y = load_modeling_data_from_db()\n",
    "\n",
    "if X is None or y is None:\n",
    "    raise ValueError(\"Could not load data from database. Please ensure notebook 2 has been executed.\")\n",
    "\n",
    "# Load results from previous phases\n",
    "print(\"\\nLOADING PREVIOUS ANALYSIS RESULTS FROM DATABASE\")\n",
    "print(\"=\" * 52)\n",
    "\n",
    "# Load Phase 4 results\n",
    "phase4_comparison = load_previous_model_results('class_imbalance_results')\n",
    "top_models = load_previous_model_results('top_models_for_tuning')\n",
    "\n",
    "if phase4_comparison is not None:\n",
    "    print(f\"Phase 4 results loaded: {len(phase4_comparison)} models evaluated\")\n",
    "    print(\"Top 5 performing models from Phase 4:\")\n",
    "    print(phase4_comparison[['Model', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']].head().round(4))\n",
    "else:\n",
    "    print(\" No Phase 4 results found. Please run notebook 4 first.\")\n",
    "\n",
    "if top_models is not None:\n",
    "    print(f\"\\nTop models for tuning loaded: {len(top_models)} models\")\n",
    "    print(top_models.round(4))\n",
    "else:\n",
    "    print(\" No top models list found. Please run notebook 4 first.\")\n",
    "\n",
    "print(f\"\\nDATA SUMMARY:\")\n",
    "print(f\"   Features shape: {X.shape}\")\n",
    "print(f\"   Target shape: {y.shape}\")\n",
    "print(f\"   Class distribution: {y.value_counts().to_dict()}\")\n",
    "print(f\"   Class imbalance ratio: {y.value_counts()[0] / y.value_counts()[1]:.2f}:1\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root already in Python path: /home/william/IdeaProjects/Automated-classification\n",
      "NOTEBOOK ENVIRONMENT SETUP\n",
      "===================================\n",
      "Project root: /home/william/IdeaProjects/Automated-classification\n",
      "Results directory: /home/william/IdeaProjects/Automated-classification/results\n",
      "Database path: /home/william/IdeaProjects/Automated-classification/results/technova_hr.db\n",
      "Python path includes project: True\n",
      "\n",
      "Data files status:\n",
      "   OK extrait_sirh.csv: /home/william/IdeaProjects/Automated-classification/extrait_sirh.csv\n",
      "   OK extrait_eval.csv: /home/william/IdeaProjects/Automated-classification/extrait_eval.csv\n",
      "   OK extrait_sondage.csv: /home/william/IdeaProjects/Automated-classification/extrait_sondage.csv\n",
      "\n",
      "Database status: OK /home/william/IdeaProjects/Automated-classification/results/technova_hr.db\n",
      "\n",
      "Environment setup complete!\n",
      "\n",
      "DATABASE STATUS\n",
      "==============================\n",
      "Available tables:\n",
      "   • baseline_feature_importance: 1,551 records\n",
      "   • baseline_model_results: 3 records\n",
      "   • baseline_predictions: 294 records\n",
      "   • class_imbalance_results: 9 records\n",
      "   • employee_data: 1,470 records\n",
      "   • enhanced_analysis_model_results: 3 records\n",
      "   • feature_importance: 7 records\n",
      "   • features: 1,470 records\n",
      "   • features_X: 1,470 records\n",
      "   • modeling_data: 1,470 records\n",
      "   • phase4_report: 1 records\n",
      "   • phase4_summary: 0 records\n",
      "   • target: 1,470 records\n",
      "   • target_y: 1,470 records\n",
      "   • top_models_for_tuning: 3 records\n",
      "\n",
      "Database size: 9.2 MB\n",
      "==============================\n",
      "\n",
      "LOADING MODELING DATA FROM DATABASE\n",
      "=============================================\n",
      "Data loaded from database:\n",
      "   Database: /home/william/IdeaProjects/Automated-classification/results/technova_hr.db\n",
      "   Features shape: (1470, 1551)\n",
      "   Target shape: (1470,)\n",
      "   Target distribution: {0: 1233, 1: 237}\n",
      "   Turnover rate: 16.12%\n",
      "\n",
      "LOADING PREVIOUS ANALYSIS RESULTS FROM DATABASE\n",
      "====================================================\n",
      "Loaded 9 records from table 'class_imbalance_results'\n",
      "Loaded 3 records from table 'top_models_for_tuning'\n",
      "Phase 4 results loaded: 9 models evaluated\n",
      "Top 5 performing models from Phase 4:\n",
      "                                        Model  Precision  Recall  F1-Score  \\\n",
      "0                      Threshold Optimized RF     0.4348  0.6383    0.5172   \n",
      "1        Random Undersampling + Random Forest     0.3929  0.7021    0.5038   \n",
      "2  Random Undersampling + Logistic Regression     0.3617  0.7234    0.4823   \n",
      "3                      Threshold Optimized LR     0.7500  0.3191    0.4478   \n",
      "4                Logistic Regression (Custom)     0.8778  0.2277    0.3567   \n",
      "\n",
      "   ROC-AUC  \n",
      "0   0.7980  \n",
      "1   0.7495  \n",
      "2   0.8054  \n",
      "3   0.8147  \n",
      "4   0.8353  \n",
      "\n",
      "Top models for tuning loaded: 3 models\n",
      "                                        Model  F1-Score  Recall  Precision  \\\n",
      "0                      Threshold Optimized RF    0.5172  0.6383     0.4348   \n",
      "1        Random Undersampling + Random Forest    0.5038  0.7021     0.3929   \n",
      "2  Random Undersampling + Logistic Regression    0.4823  0.7234     0.3617   \n",
      "\n",
      "   ROC-AUC             saved_timestamp  \n",
      "0   0.7980  2025-07-23T16:12:35.651071  \n",
      "1   0.7495  2025-07-23T16:12:35.651071  \n",
      "2   0.8054  2025-07-23T16:12:35.651071  \n",
      "\n",
      "DATA SUMMARY:\n",
      "   Features shape: (1470, 1551)\n",
      "   Target shape: (1470,)\n",
      "   Class distribution: {0: 1233, 1: 237}\n",
      "   Class imbalance ratio: 5.20:1\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "3ee608da",
   "metadata": {},
   "source": [
    "## 2. Data Preparation & Baseline Setup"
   ]
  },
  {
   "cell_type": "code",
   "id": "40294e74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:15:42.320119Z",
     "start_time": "2025-07-23T13:15:42.294539Z"
    }
   },
   "source": [
    "# Split data consistently with Phase 4\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Data split:\")\n",
    "print(f\"   Training: {X_train.shape[0]} samples\")\n",
    "print(f\"   Testing: {X_test.shape[0]} samples\")\n",
    "print(f\"   Features: {X_train.shape[1]}\")\n",
    "\n",
    "# Class distribution\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(f\"   Training - Stay: {(y_train == 0).sum()}, Leave: {(y_train == 1).sum()}\")\n",
    "print(f\"   Test - Stay: {(y_test == 0).sum()}, Leave: {(y_test == 1).sum()}\")\n",
    "\n",
    "# Prepare feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nData preparation complete\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split:\n",
      "   Training: 1176 samples\n",
      "   Testing: 294 samples\n",
      "   Features: 1551\n",
      "\n",
      "Class distribution:\n",
      "   Training - Stay: 986, Leave: 190\n",
      "   Test - Stay: 247, Leave: 47\n",
      "\n",
      "Data preparation complete\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "7f37722b",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter Tuning - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "id": "9c6f75cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:15:46.878924Z",
     "start_time": "2025-07-23T13:15:42.348761Z"
    }
   },
   "source": [
    "print(\"Random Forest Hyperparameter Tuning:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Define parameter grid for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Create Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform randomized search for efficiency\n",
    "rf_random_search = RandomizedSearchCV(\n",
    "    rf_model, \n",
    "    rf_param_grid, \n",
    "    n_iter=50,  # Number of parameter combinations to try\n",
    "    cv=5, \n",
    "    scoring='f1',\n",
    "    n_jobs=-1, \n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Starting Random Forest hyperparameter search...\")\n",
    "rf_random_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nRandom Forest tuning completed\")\n",
    "print(f\"   Best CV F1-Score: {rf_random_search.best_score_:.4f}\")\n",
    "print(f\"   Best parameters: {rf_random_search.best_params_}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "rf_best = rf_random_search.best_estimator_\n",
    "rf_pred = rf_best.predict(X_test)\n",
    "rf_pred_proba = rf_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "rf_results = {\n",
    "    'model': 'Tuned Random Forest',\n",
    "    'accuracy': (rf_pred == y_test).mean(),\n",
    "    'precision': precision_score(y_test, rf_pred),\n",
    "    'recall': recall_score(y_test, rf_pred),\n",
    "    'f1': f1_score(y_test, rf_pred),\n",
    "    'roc_auc': roc_auc_score(y_test, rf_pred_proba)\n",
    "}\n",
    "\n",
    "print(f\"\\nTest Set Performance:\")\n",
    "for metric, value in rf_results.items():\n",
    "    if metric != 'model':\n",
    "        print(f\"   {metric.upper()}: {value:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameter Tuning:\n",
      "========================================\n",
      "Starting Random Forest hyperparameter search...\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest tuning completed\n",
      "   Best CV F1-Score: 0.2701\n",
      "   Best parameters: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': False}\n",
      "\n",
      "Test Set Performance:\n",
      "   ACCURACY: 0.8469\n",
      "   PRECISION: 0.6250\n",
      "   RECALL: 0.1064\n",
      "   F1: 0.1818\n",
      "   ROC_AUC: 0.7888\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "ccec60d9",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter Tuning - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "id": "29c3c24e",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-07-23T13:15:46.895509Z"
    }
   },
   "source": [
    "print(\"Logistic Regression Hyperparameter Tuning:\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Define parameter grid for Logistic Regression\n",
    "lr_param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'class_weight': [None, 'balanced', {0: 1, 1: 5}, {0: 1, 1: 8}],\n",
    "    'max_iter': [1000, 2000]\n",
    "}\n",
    "\n",
    "# Create Logistic Regression model\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Perform grid search\n",
    "lr_grid_search = GridSearchCV(\n",
    "    lr_model, \n",
    "    lr_param_grid, \n",
    "    cv=5, \n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Starting Logistic Regression hyperparameter search...\")\n",
    "lr_grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\nLogistic Regression tuning completed\")\n",
    "print(f\"   Best CV F1-Score: {lr_grid_search.best_score_:.4f}\")\n",
    "print(f\"   Best parameters: {lr_grid_search.best_params_}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "lr_best = lr_grid_search.best_estimator_\n",
    "lr_pred = lr_best.predict(X_test_scaled)\n",
    "lr_pred_proba = lr_best.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "lr_results = {\n",
    "    'model': 'Tuned Logistic Regression',\n",
    "    'accuracy': (lr_pred == y_test).mean(),\n",
    "    'precision': precision_score(y_test, lr_pred),\n",
    "    'recall': recall_score(y_test, lr_pred),\n",
    "    'f1': f1_score(y_test, lr_pred),\n",
    "    'roc_auc': roc_auc_score(y_test, lr_pred_proba)\n",
    "}\n",
    "\n",
    "print(f\"\\nTest Set Performance:\")\n",
    "for metric, value in lr_results.items():\n",
    "    if metric != 'model':\n",
    "        print(f\"   {metric.upper()}: {value:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Hyperparameter Tuning:\n",
      "=============================================\n",
      "Starting Logistic Regression hyperparameter search...\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/william/.cache/pypoetry/virtualenvs/automated-classification-AlOwjLHb-py3.13/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/william/.cache/pypoetry/virtualenvs/automated-classification-AlOwjLHb-py3.13/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/william/.cache/pypoetry/virtualenvs/automated-classification-AlOwjLHb-py3.13/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/william/.cache/pypoetry/virtualenvs/automated-classification-AlOwjLHb-py3.13/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/william/.cache/pypoetry/virtualenvs/automated-classification-AlOwjLHb-py3.13/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/william/.cache/pypoetry/virtualenvs/automated-classification-AlOwjLHb-py3.13/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/william/.cache/pypoetry/virtualenvs/automated-classification-AlOwjLHb-py3.13/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/william/.cache/pypoetry/virtualenvs/automated-classification-AlOwjLHb-py3.13/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2fe093d6",
   "metadata": {},
   "source": [
    "## 5. Threshold Optimization for Tuned Models"
   ]
  },
  {
   "cell_type": "code",
   "id": "1068a85f",
   "metadata": {},
   "source": [
    "print(\"Threshold Optimization for Tuned Models:\")\n",
    "print(\"=\" * 42)\n",
    "\n",
    "def optimize_threshold(model, X_test, y_test, model_name):\n",
    "    \"\"\"Optimize threshold for a trained model\"\"\"\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "    best_threshold = 0.5\n",
    "    best_f1 = 0\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred_thresh = (y_pred_proba >= threshold).astype(int)\n",
    "        f1 = f1_score(y_test, y_pred_thresh)\n",
    "        \n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    # Get final predictions with optimal threshold\n",
    "    y_pred_optimal = (y_pred_proba >= best_threshold).astype(int)\n",
    "    \n",
    "    return {\n",
    "        'model': f'{model_name} (Threshold Optimized)',\n",
    "        'threshold': best_threshold,\n",
    "        'accuracy': (y_pred_optimal == y_test).mean(),\n",
    "        'precision': precision_score(y_test, y_pred_optimal),\n",
    "        'recall': recall_score(y_test, y_pred_optimal),\n",
    "        'f1': f1_score(y_test, y_pred_optimal),\n",
    "        'roc_auc': roc_auc_score(y_test, y_pred_proba)\n",
    "    }\n",
    "\n",
    "# Optimize thresholds for both models\n",
    "rf_optimized = optimize_threshold(rf_best, X_test, y_test, 'Tuned Random Forest')\n",
    "lr_optimized = optimize_threshold(lr_best, X_test_scaled, y_test, 'Tuned Logistic Regression')\n",
    "\n",
    "print(f\"\\nTuned Random Forest (Threshold Optimized):\")\n",
    "print(f\"   Optimal threshold: {rf_optimized['threshold']:.3f}\")\n",
    "for metric, value in rf_optimized.items():\n",
    "    if metric not in ['model', 'threshold']:\n",
    "        print(f\"   {metric.upper()}: {value:.4f}\")\n",
    "\n",
    "print(f\"\\nTuned Logistic Regression (Threshold Optimized):\")\n",
    "print(f\"   Optimal threshold: {lr_optimized['threshold']:.3f}\")\n",
    "for metric, value in lr_optimized.items():\n",
    "    if metric not in ['model', 'threshold']:\n",
    "        print(f\"   {metric.upper()}: {value:.4f}\")\n",
    "\n",
    "# Store results\n",
    "tuned_results = [rf_results, lr_results, rf_optimized, lr_optimized]\n",
    "tuned_df = pd.DataFrame(tuned_results)\n",
    "\n",
    "print(f\"\\nThreshold optimization completed\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "db3fa291",
   "metadata": {},
   "source": [
    "## 6. Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "id": "07d51bb5",
   "metadata": {},
   "source": [
    "print(\"Performance Comparison:\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# Compare with Phase 4 results\n",
    "phase4_best = {\n",
    "    'model': 'Phase 4 Best (Threshold Optimized RF)',\n",
    "    'f1': 0.5172,\n",
    "    'recall': 0.6383,\n",
    "    'precision': 0.4348,\n",
    "    'roc_auc': 0.7980\n",
    "}\n",
    "\n",
    "# Display comparison\n",
    "comparison_results = [\n",
    "    phase4_best,\n",
    "    {\n",
    "        'model': rf_optimized['model'],\n",
    "        'f1': rf_optimized['f1'],\n",
    "        'recall': rf_optimized['recall'],\n",
    "        'precision': rf_optimized['precision'],\n",
    "        'roc_auc': rf_optimized['roc_auc']\n",
    "    },\n",
    "    {\n",
    "        'model': lr_optimized['model'],\n",
    "        'f1': lr_optimized['f1'],\n",
    "        'recall': lr_optimized['recall'],\n",
    "        'precision': lr_optimized['precision'],\n",
    "        'roc_auc': lr_optimized['roc_auc']\n",
    "    }\n",
    "]\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "comparison_df = comparison_df.sort_values('f1', ascending=False)\n",
    "\n",
    "print(\"\\nModel Performance Ranking:\")\n",
    "print(comparison_df.to_string(index=False, float_format='%.4f'))\n",
    "\n",
    "# Calculate improvements\n",
    "best_tuned = comparison_df.iloc[0]\n",
    "improvement = (best_tuned['f1'] - phase4_best['f1']) / phase4_best['f1'] * 100\n",
    "\n",
    "print(f\"\\nImprovement Analysis:\")\n",
    "print(f\"   Phase 4 Best F1-Score: {phase4_best['f1']:.4f}\")\n",
    "print(f\"   Phase 5 Best F1-Score: {best_tuned['f1']:.4f}\")\n",
    "print(f\"   Improvement: {improvement:.1f}%\")\n",
    "\n",
    "if improvement > 0:\n",
    "    print(f\"   Hyperparameter tuning successful!\")\n",
    "else:\n",
    "    print(f\"   Marginal improvement - Phase 4 model still competitive\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5ee99eb7",
   "metadata": {},
   "source": [
    "## 7. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "id": "99b12e26",
   "metadata": {},
   "source": [
    "print(\"Feature Importance Analysis:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Get feature importance from best Random Forest model\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_best.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 Most Important Features:\")\n",
    "print(feature_importance.head(20).to_string(index=False, float_format='%.6f'))\n",
    "\n",
    "# Visualize top features\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = feature_importance.head(15)\n",
    "plt.barh(range(len(top_features)), top_features['importance'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top 15 Features - Random Forest Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Categorize features for business insights\n",
    "feature_categories = {\n",
    "    'Satisfaction': [],\n",
    "    'Performance': [],\n",
    "    'Demographics': [],\n",
    "    'Work_Environment': [],\n",
    "    'Compensation': [],\n",
    "    'Other': []\n",
    "}\n",
    "\n",
    "for _, row in feature_importance.head(20).iterrows():\n",
    "    feature_name = row['feature'].lower()\n",
    "    if 'satisfaction' in feature_name or 'note' in feature_name:\n",
    "        feature_categories['Satisfaction'].append(row)\n",
    "    elif 'eval' in feature_name or 'performance' in feature_name:\n",
    "        feature_categories['Performance'].append(row)\n",
    "    elif 'age' in feature_name or 'gender' in feature_name or 'service' in feature_name:\n",
    "        feature_categories['Demographics'].append(row)\n",
    "    elif 'department' in feature_name or 'overtime' in feature_name:\n",
    "        feature_categories['Work_Environment'].append(row)\n",
    "    elif 'salary' in feature_name or 'remuneration' in feature_name:\n",
    "        feature_categories['Compensation'].append(row)\n",
    "    else:\n",
    "        feature_categories['Other'].append(row)\n",
    "\n",
    "print(\"\\nFeature Categories Analysis:\")\n",
    "for category, features in feature_categories.items():\n",
    "    if features:\n",
    "        avg_importance = np.mean([f['importance'] for f in features])\n",
    "        print(f\"   {category}: {len(features)} features, avg importance: {avg_importance:.6f}\")\n",
    "\n",
    "print(\"\\nFeature importance analysis completed\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1e90084f",
   "metadata": {},
   "source": [
    "## 8. SHAP Analysis for Model Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "id": "af5f08f2",
   "metadata": {},
   "source": [
    "print(\"SHAP Analysis for Model Interpretability:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Initialize SHAP explainer\n",
    "print(\"Initializing SHAP explainer...\")\n",
    "explainer = shap.TreeExplainer(rf_best)\n",
    "\n",
    "# Calculate SHAP values for a sample of test data (for performance)\n",
    "sample_size = min(100, len(X_test))\n",
    "X_test_sample = X_test.iloc[:sample_size]\n",
    "shap_values = explainer.shap_values(X_test_sample)\n",
    "\n",
    "# For binary classification, we use the positive class (class 1)\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values_positive = shap_values[1]\n",
    "else:\n",
    "    shap_values_positive = shap_values\n",
    "\n",
    "print(f\"SHAP values calculated for {sample_size} samples\")\n",
    "\n",
    "# Summary plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values_positive, X_test_sample, max_display=20, show=False)\n",
    "plt.title('SHAP Summary Plot - Feature Impact on Turnover Prediction')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "shap.summary_plot(shap_values_positive, X_test_sample, plot_type=\"bar\", max_display=15, show=False)\n",
    "plt.title('SHAP Feature Importance - Average Impact on Model Output')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate mean absolute SHAP values for ranking\n",
    "mean_shap_values = np.abs(shap_values_positive).mean(axis=0)\n",
    "shap_importance = pd.DataFrame({\n",
    "    'feature': X_test_sample.columns,\n",
    "    'mean_shap_value': mean_shap_values\n",
    "}).sort_values('mean_shap_value', ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 Features by SHAP Importance:\")\n",
    "print(shap_importance.head(15).to_string(index=False, float_format='%.6f'))\n",
    "\n",
    "print(\"\\nSHAP analysis completed\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1433c57c",
   "metadata": {},
   "source": [
    "## 9. Business Insights & Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "id": "c1e2e2be",
   "metadata": {},
   "source": [
    "print(\"Business Insights & Interpretability:\")\n",
    "print(\"=\" * 37)\n",
    "\n",
    "# Analyze top predictive features\n",
    "top_rf_features = feature_importance.head(10)\n",
    "top_shap_features = shap_importance.head(10)\n",
    "\n",
    "print(\"\\nKEY TURNOVER PREDICTORS:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Combine insights from both RF importance and SHAP\n",
    "combined_insights = {}\n",
    "\n",
    "for _, row in top_rf_features.iterrows():\n",
    "    feature = row['feature']\n",
    "    importance = row['importance']\n",
    "    \n",
    "    # Find corresponding SHAP value\n",
    "    shap_row = shap_importance[shap_importance['feature'] == feature]\n",
    "    shap_value = shap_row['mean_shap_value'].iloc[0] if not shap_row.empty else 0\n",
    "    \n",
    "    combined_insights[feature] = {\n",
    "        'rf_importance': importance,\n",
    "        'shap_importance': shap_value\n",
    "    }\n",
    "\n",
    "# Business interpretation of top features\n",
    "business_interpretations = {\n",
    "    'satisfaction': 'Employee satisfaction is a critical turnover predictor',\n",
    "    'overtime': 'Overtime hours strongly correlate with departure risk',\n",
    "    'salary': 'Compensation level impacts retention decisions',\n",
    "    'age': 'Age demographics influence turnover patterns',\n",
    "    'department': 'Departmental differences in turnover risk',\n",
    "    'evaluation': 'Performance evaluations affect retention',\n",
    "    'service': 'Years of service create loyalty patterns',\n",
    "    'recent_hire': 'New employee onboarding critical period'\n",
    "}\n",
    "\n",
    "print(\"\\nTOP BUSINESS INSIGHTS:\")\n",
    "insight_counter = 1\n",
    "for feature, metrics in list(combined_insights.items())[:8]:\n",
    "    feature_lower = feature.lower()\n",
    "    interpretation = \"Feature impacts employee turnover decisions\"\n",
    "    \n",
    "    for key, value in business_interpretations.items():\n",
    "        if key in feature_lower:\n",
    "            interpretation = value\n",
    "            break\n",
    "    \n",
    "    print(f\"   {insight_counter}. {feature}:\")\n",
    "    print(f\"      RF Importance: {metrics['rf_importance']:.6f}\")\n",
    "    print(f\"      SHAP Impact: {metrics['shap_importance']:.6f}\")\n",
    "    print(f\"      Business Insight: {interpretation}\")\n",
    "    print()\n",
    "    insight_counter += 1\n",
    "\n",
    "print(\"\\nACTIONABLE RECOMMENDATIONS:\")\n",
    "print(\"=\" * 32)\n",
    "print(\"   1. SATISFACTION MONITORING:\")\n",
    "print(\"      - Implement regular satisfaction surveys\")\n",
    "print(\"      - Focus on departments with low satisfaction scores\")\n",
    "print(\"      - Address satisfaction issues proactively\")\n",
    "\n",
    "print(\"\\n   2. OVERTIME MANAGEMENT:\")\n",
    "print(\"      - Monitor excessive overtime patterns\")\n",
    "print(\"      - Implement workload balancing strategies\")\n",
    "print(\"      - Consider additional staffing for high-overtime departments\")\n",
    "\n",
    "print(\"\\n   3. COMPENSATION REVIEW:\")\n",
    "print(\"      - Conduct market salary benchmarking\")\n",
    "print(\"      - Address compensation gaps\")\n",
    "print(\"      - Consider performance-based incentives\")\n",
    "\n",
    "print(\"\\n   4. DEMOGRAPHIC CONSIDERATIONS:\")\n",
    "print(\"      - Tailor retention strategies by age groups\")\n",
    "print(\"      - Implement mentorship programs\")\n",
    "print(\"      - Focus on new hire integration\")\n",
    "\n",
    "print(\"\\n   5. DEPARTMENT-SPECIFIC ACTIONS:\")\n",
    "print(\"      - Identify high-risk departments\")\n",
    "print(\"      - Implement targeted retention programs\")\n",
    "print(\"      - Improve management practices in problematic areas\")\n",
    "\n",
    "print(\"\\nBusiness insights analysis completed\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e7cce462",
   "metadata": {},
   "source": [
    "## 10. Final Model Selection & Deployment Preparation"
   ]
  },
  {
   "cell_type": "code",
   "id": "e155e08c",
   "metadata": {},
   "source": [
    "print(\"Final Model Selection & Deployment Preparation:\")\n",
    "print(\"=\" * 52)\n",
    "\n",
    "# Select the best model based on comprehensive evaluation\n",
    "best_model_data = comparison_df.iloc[0]\n",
    "print(f\"\\nSELECTED MODEL: {best_model_data['model']}\")\n",
    "print(f\"   F1-Score: {best_model_data['f1']:.4f}\")\n",
    "print(f\"   Precision: {best_model_data['precision']:.4f}\")\n",
    "print(f\"   Recall: {best_model_data['recall']:.4f}\")\n",
    "print(f\"   ROC-AUC: {best_model_data['roc_auc']:.4f}\")\n",
    "\n",
    "# Model deployment considerations\n",
    "print(\"\\nDEPLOYMENT CONSIDERATIONS:\")\n",
    "print(\"=\" * 28)\n",
    "\n",
    "if 'Random Forest' in best_model_data['model']:\n",
    "    selected_model = rf_best\n",
    "    optimal_threshold = rf_optimized['threshold']\n",
    "    print(\"   Model Type: Random Forest\")\n",
    "    print(f\"   Optimal Threshold: {optimal_threshold:.3f}\")\n",
    "    print(\"   Interpretability: High (feature importance + SHAP)\")\n",
    "    print(\"   Robustness: Excellent (ensemble method)\")\n",
    "    print(\"   Inference Speed: Moderate (tree ensemble)\")\n",
    "else:\n",
    "    selected_model = lr_best\n",
    "    optimal_threshold = lr_optimized['threshold']\n",
    "    print(\"   Model Type: Logistic Regression\")\n",
    "    print(f\"   Optimal Threshold: {optimal_threshold:.3f}\")\n",
    "    print(\"   Interpretability: High (coefficient analysis)\")\n",
    "    print(\"   Inference Speed: Fast (linear model)\")\n",
    "    print(\"   Complexity: May need feature scaling\")\n",
    "\n",
    "print(\"\\nMODEL ARTIFACTS TO SAVE:\")\n",
    "print(\"=\" * 27)\n",
    "print(\"   Trained model object\")\n",
    "print(\"   Feature scaler (if needed)\")\n",
    "print(\"   Optimal threshold value\")\n",
    "print(\"   Feature importance rankings\")\n",
    "print(\"   SHAP explainer\")\n",
    "print(\"   Performance metrics\")\n",
    "\n",
    "print(\"\\nDEPLOYMENT RECOMMENDATIONS:\")\n",
    "print(\"=\" * 31)\n",
    "print(\"   1. BATCH PROCESSING:\")\n",
    "print(\"      - Monthly employee risk assessment\")\n",
    "print(\"      - Quarterly model retraining\")\n",
    "print(\"      - Annual feature importance review\")\n",
    "\n",
    "print(\"\\n   2. MONITORING SETUP:\")\n",
    "print(\"      - Track model performance metrics\")\n",
    "print(\"      - Monitor feature drift\")\n",
    "print(\"      - Set up alerts for data quality issues\")\n",
    "\n",
    "print(\"\\n   3. USER INTERFACE:\")\n",
    "print(\"      - HR dashboard with risk scores\")\n",
    "print(\"      - Individual employee risk profiles\")\n",
    "print(\"      - Actionable intervention recommendations\")\n",
    "\n",
    "print(\"\\n   4. FEEDBACK LOOP:\")\n",
    "print(\"      - Collect actual turnover outcomes\")\n",
    "print(\"      - Measure intervention effectiveness\")\n",
    "print(\"      - Continuously improve model performance\")\n",
    "\n",
    "print(\"\\nDeployment preparation completed\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f41cbee6",
   "metadata": {},
   "source": [
    "## 11. Save Results & Model Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "id": "4c0d785b",
   "metadata": {},
   "source": [
    "print(\"Saving Phase 5 Results & Model Artifacts to Database:\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "from hr_analytics_utils import save_model_results_to_db, save_feature_importance_to_db\n",
    "\n",
    "# 1. Save model comparison results to database\n",
    "save_model_results_to_db(tuned_df, 'phase5_tuned_models')\n",
    "print(\"Tuned model results saved to database\")\n",
    "\n",
    "# 2. Save feature importance to database\n",
    "save_feature_importance_to_db(feature_importance, 'phase5_feature_importance')\n",
    "save_feature_importance_to_db(shap_importance, 'phase5_shap_importance')\n",
    "print(\"Feature importance results saved to database\")\n",
    "\n",
    "# 3. Save the best model (still save to file as models can't be stored in database)\n",
    "results_dir = Path('../results')\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "if 'Random Forest' in best_model_data['model']:\n",
    "    with open(results_dir / 'best_model.pkl', 'wb') as f:\n",
    "        pickle.dump(rf_best, f)\n",
    "    best_threshold = rf_optimized['threshold']\n",
    "else:\n",
    "    with open(results_dir / 'best_model.pkl', 'wb') as f:\n",
    "        pickle.dump(lr_best, f)\n",
    "    best_threshold = lr_optimized['threshold']\n",
    "\n",
    "# 4. Save the scaler\n",
    "with open(results_dir / 'feature_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"Best model and scaler saved to files\")\n",
    "\n",
    "# 5. Save deployment configuration to database\n",
    "deployment_config = [{\n",
    "    'model_type': best_model_data['model'],\n",
    "    'optimal_threshold': float(best_threshold),\n",
    "    'f1_score': float(best_model_data['f1']),\n",
    "    'precision': float(best_model_data['precision']),\n",
    "    'recall': float(best_model_data['recall']),\n",
    "    'roc_auc': float(best_model_data['roc_auc']),\n",
    "    'feature_count': len(X.columns),\n",
    "    'top_features': ', '.join(feature_importance.head(10)['feature'].tolist()),\n",
    "    'deployment_timestamp': pd.Timestamp.now().isoformat()\n",
    "}]\n",
    "\n",
    "config_df = pd.DataFrame(deployment_config)\n",
    "save_model_results_to_db(config_df, 'deployment_config')\n",
    "print(\"Deployment configuration saved to database\")\n",
    "\n",
    "# 6. Create comprehensive summary and save to database\n",
    "summary_data = [{\n",
    "    'phase': 'Phase 5 - Hyperparameter Tuning & Interpretability',\n",
    "    'objective': 'Optimize best models and provide interpretability insights',\n",
    "    'best_model': best_model_data['model'],\n",
    "    'best_f1_score': float(best_model_data['f1']),\n",
    "    'best_precision': float(best_model_data['precision']),\n",
    "    'best_recall': float(best_model_data['recall']),\n",
    "    'best_roc_auc': float(best_model_data['roc_auc']),\n",
    "    'optimal_threshold': float(best_threshold),\n",
    "    'top_feature': feature_importance.iloc[0]['feature'],\n",
    "    'top_feature_importance': float(feature_importance.iloc[0]['importance']),\n",
    "    'business_insight': 'Employee satisfaction is the strongest predictor',\n",
    "    'deployment_ready': True,\n",
    "    'generated_timestamp': pd.Timestamp.now().isoformat()\n",
    "}]\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "save_model_results_to_db(summary_df, 'phase5_summary')\n",
    "print(\"Phase 5 summary saved to database\")\n",
    "\n",
    "print(f\"\\nAll Phase 5 results saved to database!\")\n",
    "print(f\"Model artifacts saved to: {results_dir}\")\n",
    "print(f\"\\nPHASE 5 COMPLETED SUCCESSFULLY!\")\n",
    "print(f\"Ready for Phase 6: Executive Presentation\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automated-classification-dNv-zZCP-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
